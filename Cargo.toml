[workspace]
members = [
    "backends",
    "backends/vllm",
    "csrc",
    "help",
    "models",
    "server",
]
resolver = "2"

[workspace.package]
version = "0.1.0"
edition = "2021"

[workspace.dependencies]
anyhow = "1.0.89"
async-openai = "0.24.1"
axum = "0.7"
atoma-backends = { path = "./backends/" }
bindgen_cuda = "0.1.5"
candle-core = "0.7.2"
candle-nn = "0.7.2"
candle-transformers = "0.7.2"
candle-examples = "0.7.2"
clap = "4.5.18"
config = "0.14.0"
csrc = { path = "csrc" }
cudarc = { version = "0.12.0", features = [
    "std",
    "cublas",
    "cublaslt",
    "curand",
    "driver",
    "nvrtc",
    "f16",
    "cuda-version-from-build-system",
    "dynamic-linking",
], default-features = false }
cuda-runtime-sys = "0.3.0-alpha.1"
dotenv = "0.15.0"
expect-test = "1.5"
flume = "0.11.0"
futures = "0.3.30"
half = "2.4.1"
help = { path = "help" }
hf-hub = "0.3.2"
indexmap = "2.2.6"
metrics = "0.23"
metrics-exporter-prometheus = "0.14.0"
models = { path = "models" }
rand = "0.8.5"
serde = "1.0.204"
serde_json = "1.0.120"
serial_test = "3.1.1"
sys-info = "0.9.1"
thiserror = "1.0.64"
tokenizers = "0.19.1"
tokio = "1.40.0"
tracing = "0.1.40"
tracing-subscriber = "0.3.18"
utoipa = "4.2.3"
utoipa-swagger-ui = "7.1.0"
